\documentclass[letterpaper, 12pt]{article}
\usepackage[margin=2cm,textwidth=19cm]{geometry}
%\usepackage[nomarkers]{endfloat} %%%%%%%%%
\usepackage{calc}
\usepackage{color}
\usepackage{dsfont}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{graphicx}
\usepackage{float}
% Create new "listing" float
\newfloat{listing}{tbhp}{lst}%[section]
\floatname{listing}{Listing}
\newcommand{\listoflistings}{\listof{listing}{List of Listings}}
\floatstyle{plaintop}
\restylefloat{listing}
 
\usepackage{natbib}
%\usepackage{multind}
\usepackage{booktabs}
\usepackage{enumerate}
\usepackage{todonotes}
% \usepackage{uarial}
% \renewcommand{\familydefault}{\sfdefault}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% to change %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \usepackage{lineno}
%% \linenumber
\renewcommand{\baselinestretch}{1}  %% 2

\usepackage{color,xcolor}
\definecolor{link}{HTML}{004C80}

\usepackage[labelfont=bf]{caption}
\usepackage[english]{babel}
\usepackage[
  pdftex,
  plainpages=false,
  pdfpagelabels,
  pagebackref=true,
  colorlinks=true,
  citecolor=link,
  linkcolor=link
]{hyperref}
\hypersetup{colorlinks,urlcolor=link}
\usepackage{array, lipsum}

% \usepackage{datetime}
\usepackage[margin=2cm,textwidth=19cm]{geometry}
\usepackage{float}

% tikz related definitions
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows}

\tikzstyle{once} = [rectangle, rounded corners, 
minimum width=3cm, 
minimum height=1cm, text centered, 
draw=black, fill=green!30]

\tikzstyle{more} = [rectangle, rounded corners, 
minimum width=3cm, 
minimum height=1cm, text centered, 
draw=black, fill=yellow!30]

\tikzstyle{most} = [rectangle, rounded corners, 
minimum width=3cm, 
minimum height=1cm, text centered, 
draw=black, fill=red!30]

\tikzstyle{decision} = [diamond, 
minimum width=3cm, 
minimum height=1cm, 
text centered, 
draw=black, 
fill=blue!30]

\tikzstyle{arrow} = [thick,->,>=stealth]

% define some commands
\newcommand{\eg}{{e.\,g.\,}}
\newcommand{\ie}{{i.\,e.\,}}
\newcommand{\pkg}[1]{\textit{#1}}


\newcommand{\N}{\mathcal{N}}

\setlength\parindent{0pt}

%\newcommand{\todo}[1]{\textcolor{red}{#1}}

\makeatletter
\DeclareRobustCommand*\textsubscript[1]{%
  \@textsubscript{\selectfont#1}}
\def\@textsubscript#1{%
  {\m@th\ensuremath{_{\mbox{\fontsize\sf@size\z@#1}}}}}
\makeatother


\begin{document}
\begin{center}
  {\noindent \LARGE \bf Code documentation for the simulation study:\\[2mm]
    Comparison of confidence intervals summarizing\\[2mm]
    the uncertainty of the combined estimate of a meta-analysis
  }\\
\bigskip
{\noindent \Large Felix Hofmann
}\end{center}
\bigskip
\vspace*{.5cm}

\tableofcontents

\newpage 

\section{Overview} \label{sec:overview}

This document gives an overview over the code that implements the
simulation study \emph{Comparison of confidence intervals summarizing the
uncertainty of the combined estimate of a meta-analysis}.


\subsection{Terminology} \label{subsec:term}

In order to understand make the contents of this document more clear, the
following terminology is used:

\begin{description}
  \item [grid] A \texttt{data.frame} with columns:
    \begin{description}
      \item [\texttt{sampleSize}] The sample size for all of the studies in the
        meta-analysis.
      \item [\texttt{effect}] The true effect $\theta$ in the meta-analysis.
        Here we use $\theta \in \{0.1, 0.2, 0.5\}$.
      \item [\texttt{I2}] Higgin's $I^2$, \ie, the proportion of the variability
        in the meta-analysis that is explained by between-study heterogeneity
        rather than sampling error. Here we use $I^2 \in \{0, 0.3, 0.6, 0.9\}$.
      \item [\texttt{k}] The number of studies in a given meta-analysis data
        set. In this simulation we use $k \in \{3, 5, 10, 20, 50\}$.
      \item [\texttt{heterogeneity}] The heterogeneity model used in simulation.
        Currently, this is always \texttt{"additive"}.
        % This is either \texttt{"additive"} or \texttt{"multiplicative"}.
      \item [\texttt{dist}] The distribution of the individual study effects.
        This is either \texttt{"Gaussian"} or \texttt{"t"}. The distribution
        always has mean $\theta$.
      \item [\texttt{bias}] The publication bias. This is one of
        \texttt{"none"}, \texttt{"moderate"}, or \texttt{"strong"}.
      \item [\texttt{large}] The number of large studies in the meta-analysis.
        These large studies have $10 \cdot$ \texttt{sampleSize} participants.
        Currently, we use $\text{large} \in \{0, 1, 3\}$.
    \end{description}
  \item [method] With the term \emph{method} we refer to a specific method used
    to calculate a confidence interval (CI) or point estimate. The methods of
    interest in this simulation are currently \emph{Edgington}
    \citep{edgington:72} and \emph{Fisher} \citep{fisher:34}.
    As reference methods we use \emph{Hartung-Knapp} \citep{IntHoutIoannidis},
    \emph{Henmi-Copas} \citep{henm:copa:10}, and the well-known
    \emph{Random Effects} model.
  \item [parameters] In the context of this document, we use the term
    \emph{parameters} to refer to a set of values that determines the simulation
    and assessment process within the simulation. Usually this is one row of
    \texttt{grid} (see above). In the code base, this variable appears as
    \texttt{pars}.
  \item [N] The number of times we repeat the simulation and assessment
    of the confidence intervals and point estimates for all parameters. In the
    code base, this variable appears as \texttt{N}.
  \item [heterogeneity estimation method] The method used to estimate the
    between-study heterogeneity $\tau^2$. Currently, we use the four methods
    \texttt{"none"}, \texttt{"DL"}, \texttt{"PM"}, and \texttt{"REML"}. Method
    \texttt{"none"} means that we set $\tau^2 \stackrel{!}{=} 0$, while method
    \texttt{"DL"} refers to the method of \citet{ders:lair:86}, \texttt{"PM"}
    denotes the method of \citet{paul:man:82}, and \texttt{"REML"} refers to the
    method of \citet{harv:77}.
  \item [performance measure] With the term \emph{performance measures} we refer
    to the measures we use to assess the CI(s) and point estimate(s) for one
    single method and one single meta-analysis data set. As performance measures
    for CIs, we currently record the width of the CI (\texttt{width}), the score
    of the CI (\texttt{score}), the coverage of the true effect, \ie,
    $\mathds{1}_{\theta \in \text{CI}}$ (\texttt{coverage\_true}), and the number of
    confidence intervals (\texttt{n}). Regarding the point estimate(s), we only
    record the estimate itself.
  \item [summary measure] We define a \emph{summary measure} as a measure that
    summarizes various records of a \emph{performance measure} for a given
    method and fixed parameters. For CIs we use the mean to summarise the
    performance measures. For point estimates, we use mean squared error (MSE),
    bias, and variance. Moreover, we calculate the relative frequencies for the
    number of CIs.
\end{description}

\subsection{Simulation details} \label{subsec:sim}

The aim of this simulation is to assess the performance of novel estimation
methods (\emph{Fisher}, \emph{Edgington}) for point estimates and confidence
intervals in meta-analyses in comparison to established methods
(\emph{Hartung-Knapp}, \emph{Henmi-Copas}, \emph{Random Effects}).

\vspace*{.5cm}

Thus, we have designed the simulation procedure as shown in
Figure~\ref{fig:flow}. The implementation of the procedure can be found in the
in function \texttt{sim()}, which is defined in file \texttt{simulation.R}.
This process needs two inputs, a \emph{grid of parameters} and $N$, the number
times we repeat the simulation and assessment of the CIs and point estimates
for each set of parameters defined in the \texttt{grid}. With these two inputs,
the simulation starts the first step by initialising a list (variable \texttt{o}
in the code) in which the summary measures are ultimately stored. The second step
is to extract a set of parameters (variable \texttt{pars} in the code) that is
later used for the simulation and assessment of the CIs and point estimates. The
third step consists of the initialization of two further variables (\texttt{av},
\texttt{p\_accept} in the code) that store the performance measures of one
simulated data set. Fourth, the following process is repeated $N$ times:
\begin{enumerate}
  \item Simulate a meta-analysis using the current parameters.
  \item Estimate the between-study heterogeneity $\tau^2$ using all heterogeneity
    estimation methods \texttt{"none"}, \texttt{"DL"}, \texttt{"PM"}, and
    \texttt{"REML"}.
  \item For each estimate of $\tau^2$, calculate the CIs and point estimates
    using all methods, \ie, \emph{Edgington}, \emph{Fisher}, \emph{Hartung-Knapp},
    \emph{Henmi-Copas}, and \emph{Random Effects}.
  \item Calculate the performance measures for resulting CI and point estimate.
  \item Store the performance measures in variables \texttt{av} and
    \texttt{p\_accept}.
\end{enumerate}
Fifth, the summary measures are calculated from the estimates using the same
heterogeneity estimation method and CI construction method. Sixth, the performance
measures are stored in the output list \texttt{o}. Seventh, the simulation did
not go through all parameters sets yet, the process goes back to step two with
new parameters. Otherwise, the simulation process stops and returns the output
list \texttt{o}.

\begin{figure}[H]
\begin{center}
\begin{tikzpicture}[node distance=1.75cm]

\node (init) [once, font=\footnotesize] {Initialise list for summary measures:
  \texttt{o}};
\node (pars) [more, below of=init, font=\footnotesize] {Get one set of
  parameters (\texttt{pars}) from \texttt{grid}};
\node (initvars) [more, below of=pars, font=\footnotesize] {
  Initialize variables for performance measures: \texttt{av}, \texttt{p\_accept}};
\node (dec) [decision, align=left, below of=initvars, yshift=-1cm,
  font=\footnotesize] {Evaluated $N$\\ data sets yet?};
\node (calcsum) [more, align=left, below of=dec,
  xshift=-4cm, yshift=-1cm, font=\footnotesize] {
  Calculate summary measures using\\ measures in variables
  \texttt{av}, \texttt{p\_accept}};
\node (sim) [most, align=left, below of=dec, xshift=4cm, yshift=-1cm,
  font=\footnotesize] {1. Simulate one data\\ set using \texttt{pars}};
\node (tau) [most, align=left, below of=sim, font=\footnotesize] {
  2. Estimate $\tau^2$ with all\\ heterogeneity estimation\\ methods};
\node (ci) [most,align=left, below of=tau, font=\footnotesize, yshift=-0.5cm] {
  3. Calculate CIs with methods \emph{Edgington},\\ \emph{Fisher},
  and \emph{Random effects} for all $\tau^2$,\\
  with methods \emph{Hartung-Knapp} and\\ \emph{Henmi-Copas}
  only for estimation\\ method \emph{REML}};
\node (meas) [most, below of=ci, font=\footnotesize, yshift=-0.5cm] {5.
  Calculate performance measures};
\node (store) [most, align=left, below of=meas, font=\footnotesize] {
  5. Store performance measures\\ in variables \texttt{av},
  \texttt{p\_accept}};
\node (storesum) [more, below of=calcsum, font=\footnotesize] {Store summary
  measures in output list \texttt{o}};
\node (dec2) [decision, align=left, below of=storesum,
  yshift=-1cm, font=\footnotesize] {
  Evaluated\\ all sets of\\ parameters?};
\node (ret) [once, below of=dec2, font=\footnotesize, yshift=-1cm] {
  Return list of summary measures \texttt{o}};

\draw [arrow] (init) -- (pars);
\draw [arrow] (pars) -- (initvars);
\draw [arrow] (initvars) -- (dec);
\draw [arrow] (dec) -- node[anchor=north west] {yes} (calcsum);
\draw [arrow] (dec) -- node[anchor=north east] {no} (sim);
\draw [arrow] (sim) -- (tau);
\draw [arrow] (tau) -- (ci);
\draw [arrow] (ci) -- (meas);
\draw [arrow] (meas) -- (store);
\draw [arrow] (store) -| (dec);
\draw [arrow] (calcsum) -- (storesum);
\draw [arrow] (storesum) -- (dec2);
\draw [arrow] (dec2) -- node[anchor=east] {yes} (ret);
\draw [arrow] (dec2) --  node[anchor=west, above=2pt] {no} ++(-4,0) |- (pars);
\end{tikzpicture}
\end{center}
  \caption{Flow chart of the simulation procedure. The colors indicate
  different scopes of the procedure, \ie, green nodes are only executed once
  in total, yellow nodes are executed once for each set of parameters, and red
  nodes are executed $N$ times for each set of parameters. The blue diamonds
  represent decision nodes.}
  \label{fig:flow}
\end{figure}


\section{Structure of the code base} \label{sec:ov:proj-struct}

The code is split into seven different files that all implement different aspects
of the simulation process in Subsection~\ref{subsec:sim}. A list of these seven
files is shown below.

\begin{itemize}
  \item \emph{simulation.R}
  \item \emph{utils.R}
  \item \emph{study\_simulation.R}
  \item \emph{studies2cis.R}
  \item \emph{cis2measures.R}
  \item \emph{measures2summary.R}
  \item \emph{plot\_results.R}
\end{itemize}

Each of these files contains functionality related to one particular step in the
simulation. The main file is \emph{simulation.R}, which sources all of the
other scripts,with the exception of \emph{plot\_results.R}. The sourced files,
\ie, \emph{utils.R}, \emph{study\_simulation.R}, \emph{studies2cis.R},
\emph{cis2measures.R}, and \emph{measures2summary.R} only contain function
definitions, no other objects. A more detailed overview of the contents of each
file can be found in the following subsections.


\subsection{simulation.R}

This is the main file of the simulation. The code in this file does the
following:

\begin{enumerate}
  \item Load necessary libraries.
  \item Source the other files that implement parts of the simulation.
  \item Define the function \texttt{sim()}, which contains the logic for the
    green, yellow, and blue nodes shown in Figure~\ref{fig:flow}.
  \item Define the object \texttt{grid}, a \texttt{data.frame} containing all
    parameter combinations.
  \item Set the number of iterations \texttt{N}.
  \item Set the number of cores \texttt{cores}, the simulation should be run on.
  \item Starts the simulation
\end{enumerate}

All other functionality is defined in the other files or the \emph{R}-package
\pkg{confMeta}.

\subsection{utils.R}

<<utils,include=FALSE>>=
source("utils.R")
@


The file \texttt{utils.R} defines two helper functions that are used in various
other functions throughout the simulation.

\begin{description}
  \item [\texttt{rep2()}] A simple utility function that wraps the base
    \emph{R} function \texttt{rep()}. The main difference is that it accepts
    vector inputs for arguments \texttt{each} or \texttt{times}.
  \item [\texttt{error\_function()}] A logger function that is only used within
    \texttt{tryCatch()} blocks. In case of errors, the function saves the error
    message to a file called \emph{error.txt}. It also stores the current
    parameters (passed through argument \texttt{args}) to a file called
    \emph{pars.rds}, and the last object received (argument \texttt{error\_obj})
    to a file called \emph{error.rds}.
\end{description}


\paragraph{Note: parallel execution}\mbox{}\\
The simulation uses the \pkg{foreach}-package \citep{foreach} as a parallel
backend with the \pkg{doRNG}-package for ensuring that the random numbers
generated inside different \texttt{for} loops are independent and reproducible.
This setup has, however, the drawback that without manual error handling, the
simulation continues exection until all scenarios finished, even if some of the
loops throw errors. This is, of course, rather undesirable since the simulation
might run for a long time even if there are errors already in the first few
iterations. Thus, all functions that simulate studies, calculate CIs,
calculate performance measures, or calculate summary measures are wrapped in a
\texttt{tryCatch()} block that calls \texttt{error\_function()} in case of an
error. The \texttt{error\_function()} will then create a the file
\emph{error.txt}. The simulation then checks in each iteration whether this file
exists, and if so, just writes \texttt{"skipped"} into the output list
\texttt{"o"} without computing anything. This, however, means that before
restarting the simulation, the \emph{error.txt} file must be deleted.

\subsection{study\_simulation.R}

<<study_simulation, include=FALSE>>=
source("study_simulation.R")
@

The script \emph{study\_simulation.R} contains all functions related to
the simulation of a meta-analysis data set. Such a data set consists of a
number of individual studies that are simulated as described in the simulation
protocol.

The file contains the definitions of the following functions.

\begin{description}
  \item [\texttt{simRE()}] Simulates a meta-analysis data set. The inputs for
    this function are \texttt{k}, \texttt{sampleSize}, \texttt{effect},
    \texttt{I2}, \texttt{heterogeneity}, \texttt{dist}, and \texttt{large}. For
    a more detailed explanation on what these arguments mean, see
    Subsection~\ref{subsec:term} under \textbf{grid}. The function returns a
    matrix with columns \texttt{theta}, \texttt{se}, and
    \texttt{delta} which correspond to the observed study-specific effects, the
    corresponding standard errors, and the true study-specific effects,
    respectively.
  \item [\texttt{pAccept()}] Calculates the acceptance probability for a given
    study under publication bias. The function is only called if the argument
    \texttt{bias} in function \texttt{simREbias()} is either \texttt{"moderate"}
    or \texttt{"strong"}.
  \item [\texttt{simREbias()}] Simulates a meta-analysis data. Under the hood
    this function just calls \texttt{simRE()} in order to simulate meta-analyses
    with \texttt{k} studies. In a second step, the publication bias is
    incorporated if \texttt{bias} $\neq$ \texttt{"none"}. This is achieved by
    calculating the acceptance probabilities using \texttt{pAccept()} and
    sampling from a binomial distribution which studies
    to keep. If the number of accepted studies is smaller than \texttt{k}, this
    process is repeated until the meta-analysis has exactly \texttt{k} studies.
    In the third step, large studies are sampled and added to the meta-analysis
    if \texttt{large} $\neq$ 0. It outputs a matrix with the same format as
    \texttt{simRE()} but it also attaches an attribute \texttt{p\_accept} to the
    matrix indicating the mean acceptance probability for each study in the
    meta-analysis. This attribute contains the value that is stored in as a
    performance measure in the variable \texttt{p\_accept} mentioned in
    Figure~\ref{fig:flow}.
  \item [\texttt{sim\_effects()}] This is the main function for simulating
    studies. Internally, it calls \texttt{simREbias()} and if that errors, runs
    \texttt{error\_function()} such that the error is documented.
\end{description}

In the simulation, we exclusively use the function \texttt{sim\_effects()} as
shown below:

<<>>=
# define the grid
grid <- expand.grid(
    # sample size of trial
    sampleSize = 50,
    # average effect, impacts selection bias
    effect = c(0.1, 0.2, 0.5),
    # Higgin's I^2 heterogeneity measure
    I2 = c(0, 0.3, 0.6, 0.9),
    # number of studies
    k = c(3, 5, 10, 20, 50),
    # The heterogeneity model that the studies are simulated from
    heterogeneity = c("additive"),
    # distribution
    dist = c("Gaussian", "t"),
    # bias
    bias = c("none", "moderate", "strong"),
    # number of large studies
    large = c(0, 1, 2),
    stringsAsFactors = FALSE
)
# get a set of parameters
print(pars <- grid[324, ])
# simulate studies
print(studies <- sim_effects(pars, i = 1))
@


\subsection{studies2cis.R}

<<studies2cis, include=FALSE>>=
source("studies2cis.R")
@


The file \emph{studies2cis.R} contains the functionality to convert a
simulated meta-analysis data set into CIs, the point estimate, and the maximum
$p$-value function, if applicable. Since we needed to implement this
functionality for all different methods, this file contains a comparatively
large number of functions. Thus, instead of listing every single function and
describing what it does, I will rather focus on the structure of how the
necessary function is implemented.

\subsubsection{Estimating heterogeneity}

In order to estimate the between-study heterogeneity $\tau^2$ with all of the
heterogeneity estimation method, the simulation includes the function
\texttt{get\_tau2()}.

\subsubsection{Reference methods}

Since we use external libraries for the calculation of CIs and point estimates
for methods \emph{Random effects} (\pkg{meta}), \emph{Hartung-Knapp} (\pkg{meta})
and \emph{Henmi-Copas} (\pkg{metafor}), the file contains wrapper functions for
these libraries. All of these libraries follow the same pattern, \ie, they
provide a function of the simulated estimates and the simulated standard
estimates in the meta-analysis data set and return a resulting object, from
which the CI and point estimate can be extracted. Thus, the extraction of the
CI and estimate is essentially only a function of the desired method, the
simulated study effects, and the corresponding standard errors.

\vspace*{0.5cm}

This idea is implemented in the function \texttt{get\_classic\_intervals()},
which takes three arguments, \texttt{methods}, \texttt{thetahat}, \texttt{se}.
Here, \texttt{methods} can be any combination of \texttt{"hk\_ci"} (for
\emph{Hartung-Knapp}), \texttt{"hc\_ci"} (for \emph{Henmi-Copas}),
\texttt{"reml\_ci"} (for \emph{Random effects}). The arguments \texttt{thetahat}
and \texttt{se} are just the simulated studies and the corresponding standard
errors from the simulation step. Internally, \texttt{get\_classic\_intervals()}
determines, what kind of object it needs to fit for each of the different
\texttt{methods} and how to extract the desired statistics.

\vspace*{0.5cm}

The internal implementation consists of functions
\texttt{get\_classic\_obj\_xx()} where \texttt{xx} is either \texttt{hc},
\texttt{reml} or \texttt{hc}. There is also a function for \texttt{bm}, which
corresponds to the \emph{bayesmeta} method, but that is currently not used. All
of these functions accept an argument \texttt{thetahat} and \texttt{se} and
return an object. Moreover, these functions are summarised in
\texttt{get\_classic\_obj()} which, depending on the \texttt{method} argument
calls one of the former functions.

\vspace*{0.5cm}

Similarly, there is a function \texttt{get\_classic\_interval()}, which calls,
depending on the \texttt{method} argument, one of the functions
\texttt{get\_classic\_yy\_xx()}, where \texttt{yy} is either \texttt{ci} (for CI)
or \texttt{pi} (for prediction interval (PI)) and \texttt{xx} is again one of
\texttt{hc}, \texttt{hk}, or \texttt{reml}. This can be used as shown in the
following code chunk.

<<>>=
# fit an object using Hartung-Knapp and extract the confidence interval
get_classic_interval(
    # alternatively, this could also be "hk_pi" for prediction interval
    method = "hk_ci",
    obj = get_classic_obj(
        method = "hk",
        thetahat = studies[, "theta"],
        se = studies[, "se"]
    )
)
@

\subsubsection{Methods of interest}

The implementation of the $p$-value functions and the algorithm that calculates
the CIs and point estimates can be found in the package \pkg{confMeta}. However,
this simulation also provides several wrappers for the confMeta functionality.

The most two most basic functions are \texttt{get\_p\_value\_functions()}, which
returns a list of all the $p$-value functions that should be present in the
simulation, and \texttt{get\_p\_value\_args()}, which returns a list of argument
configurations that are passed to the $p$-value functions.

The function \texttt{get\_new\_ci\_gamma()} calculates a grid from the lists
returned by the two functions above, loops over this list and calculates for
each argument/function combination the CI and the point estimate.

The function \texttt{get\_new\_intervals()} combines all the above functions and
serves as the main function to calculates everything of interest related to the
methods of interest.


\subsubsection{Assembling the output}

The main function for this step in the simulation is called \texttt{calc\_ci()}
which itself wraps \texttt{sim2CIs()}. The latter calculates the CIs and point
estimates for the reference methods and the methods of interests for all
possible argument configurations and returns a list with elements

\begin{description}
    \item[CIs] A \texttt{data.frame} containing the confidence interval for each
        method/argument combination. It also contains the variables
        \texttt{is\_new}, \texttt{is\_ci}, and \texttt{is\_pi}, which all
        contain logical values \texttt{TRUE} or \texttt{FALSE}. These are
        important in the next step to determine which performance maesures need
        to be calculated for a given CI.
    \item[estimates] A \texttt{data.frame} containing the point estimates for
        each method/argument combination.
    \item[p\_max] A \texttt{data.frame} containing the maximum of the $p$-value
        function for each method/argument combination.
    \item[model] The simulation model that the meta-analysis data set was
        simulated from. This is the same as \texttt{pars\$heterogeneity} and is
        independent of the \texttt{heterogeneity} argument of any $p$-value
        function used here.
    \item[theta] The simulated effects of the individual studies in the
        meta-analysis data set. This is the same as the column \texttt{"theta"}
        from the meta-analysis data set.
    \item[delta] The study-specific effects in the meta-analysis data set. This
        is the same as the column \texttt{"delta"} from the meta-analysis data
        set.
    \item[effect] The true effect used for the simulation of the meta-analysis
        data set. This is the same as \texttt{pars\$effect} for the current
        iteration.
\end{description}

\subsection{cis2measures.R}

The file \emph{cis2measures.R} contains functionality to convert the output of
function \texttt{calc\_ci()} to the performance measures stated in
Subsection~\ref{subsec:term}. The main function here is called
\texttt{calc\_measures()}, which wraps \texttt{CI2measures()} and, in case of an
error, runs the \texttt{error\_function()}.

\vspace*{0.5cm}

Internally, we first determine, which performance measure needs to be calculated
for a given CI. This is done by looking at the combination of booleans in the
variables \texttt{is\_new}, \texttt{is\_ci}, and \texttt{is\_pi} in function
\texttt{get\_measures()}. This function returns a list, that contains all the
functions needed to calculate the performance measures for the given CI.
Currently, we use the following functions to calculate the performance measures:

\begin{description}
  \item[\texttt{calc\_coverage\_true()}] Calculates the coverage of the true
      effect $\theta$. Thus, the return is 1, if $\theta \in \text{CI}$ and 0
      otherwise. This is done for all CIs.
  \item[\texttt{calc\_width()}] Calculates the width of the CI. This is done for
      all CIs.
  \item[\texttt{calc\_score()}] Calculates the score of the CI. This is done for
      all CIs.
  \item[\texttt{calc\_n()}] Calculates the number of confidence intervals. This
      is only done for CIs from methods of interest, \ie, where \texttt{is\_new
        == TRUE}.
  \item[\texttt{calc\_estimate()}] Simply returns the point estimate itself.
\end{description}

The main output of the function \texttt{calc\_ci()} is a \texttt{data.frame}
with columns

\begin{description}
    \item[value] The value of the performance measure.
    \item[measure] The name of the performance measure.
    \item[method] The name of the CI construction method.
    \item[is\_ci] Whether the current interval is a CI.
    \item[is\_pi] Whether the current interval is a PI.
    \item[is\_new] Whether the construction method is a method of interest.
\end{description}

\subsection{measures2summary.R}

This script contains the functionality needed to summarise the performance
measures to summary measures. Again, the wrapper function is
\texttt{calc\_summary\_measures()} which calls \texttt{get\_summary\_measures()}
or, in case of an error, \texttt{error\_function()}.

\vspace*{0.5cm}

Internally, we use the following functions to summarise the performance
measures.

\begin{description}
    \item[\texttt{get\_mean\_stats()}] Calculates the mean across all
        performance measures of the same method.
    \item[\texttt{get\_gamma\_stats()}] Calculates the maximum, third quartile,
        median, mean, first quartile, and minimum across the performance measure
        \emph{n}, \ie, the number of CIs.
    \item[\texttt{get\_n\_stats()}] Calculates how often the number of CIs is
        equal to $\{0, \dots, 9\}$ or $> 9$.
    \item[\texttt{get\_bias\_var\_stats()}] Calculates the mean squared error,
        bias and variance from the point estimates of each method.
    \item[\texttt{get\_paccept\_stats()}] Calculates the mean of the average
        acceptance probability. This is only done in case the current parameters
        have a bias which is not \texttt{"none"}.
\end{description}


\subsection{plot\_results.R}

This script does is not a part of the simulation itself, but it visualizes the
results of the simulation used to visualise the results.


\newpage
\bibliographystyle{apalike}
\bibliography{biblio.bib}


\end{document}
